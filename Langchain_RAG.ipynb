{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyoti-jha/openai-training/blob/main/Langchain_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Langchain\n"
      ],
      "metadata": {
        "id": "i7RNuCIqZht_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing Helper Packages"
      ],
      "metadata": {
        "id": "T2_P7Q5BfRAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-openai\n",
        "!pip install langchain-community langchain-core\n",
        "!pip install -qU langchain_community pypdf\n",
        "!pip install -qU langchain-openai\n",
        "!pip install -qU langchain_chroma"
      ],
      "metadata": {
        "id": "MeQDLY_YjR-8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c74f62f-dea3-491a-9004-d425b6c9b12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.16)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.2.38)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.16 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.16)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.115)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.16->langchain-community) (0.2.4)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "model = AzureChatOpenAI(\n",
        "        azure_endpoint=\"https://eygroup02.openai.azure.com/\",\n",
        "        azure_deployment=\"Gropu2Lang\",\n",
        "        openai_api_version=\"2024-06-01\",\n",
        "        api_key=\"c533939b29764cd4a03ff02f1d831057\"\n",
        "    )"
      ],
      "metadata": {
        "id": "L2e0x-WGjMks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.invoke(\"Hi! What day is today\")\n",
        "res.content"
      ],
      "metadata": {
        "id": "1WzkmDeRj-km",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f5b49819-8065-4359-8b05-65efe32d6b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Today is Wednesday.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqzXWAJfrhYp",
        "outputId": "4aee874f-872a-4d3d-946d-6f44c29b5e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  Telco-Customer-Churn.csv  Telco_Customer_Churn_Prediction.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Prepare PDF"
      ],
      "metadata": {
        "id": "lsngvIsOfeS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "pdf_file = \"Telco_Customer_Churn_Prediction.pdf\"\n",
        "loader = PyPDFLoader(pdf_file)\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "fXBJAysaSHhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"len:\",len(docs),\"\\n\",\"content:\",docs[0].page_content[0:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3qHfHytcNTQ",
        "outputId": "4afb87da-fcf3-4c78-851b-c8ae0b1ebd3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len: 9 \n",
            " content: Highlights in Science, Engineering and Technology  SDPIT  2024 \n",
            "Volume 92 (2024)  \n",
            " \n",
            "218 Telco Custo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configuring Azure OpenAI\n",
        "Notice how we're using different endpoints for Embeddings and Completion"
      ],
      "metadata": {
        "id": "FQTKZyzMqb9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AZURE_OPENAI_ENDPOINT = \"https://eygroup02.openai.azure.com/\"\n",
        "AZURE_OPENAI_EMBEDDINGS_ENDPOINT=\"https://eygroup02.openai.azure.com/openai/deployments/Group2-ada/embeddings?api-version=2023-05-15\"\n",
        "AZURE_OPENAI_DEPLOYMENT_NAME = \"Gropu2Lang\"\n",
        "AZURE_OPENAI_API_VERSION = \"2024-06-01\"\n",
        "AZURE_OPENAI_API_KEY = \"c533939b29764cd4a03ff02f1d831057\""
      ],
      "metadata": {
        "id": "HQo_jkf8lf7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
        "os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = AZURE_OPENAI_DEPLOYMENT_NAME\n",
        "os.environ[\"AZURE_OPENAI_API_VERSION\"] = AZURE_OPENAI_API_VERSION\n",
        "os.environ[\"AZURE_OPENAI_EMBEDDINGS_ENDPOINT\"] = AZURE_OPENAI_EMBEDDINGS_ENDPOINT\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "RtzEt6faqTu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI\n",
        "model = AzureChatOpenAI(\n",
        "    azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
        "    azure_deployment = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
        "    openai_api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
        ")"
      ],
      "metadata": {
        "id": "ieJzZ65R-dZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess PDF"
      ],
      "metadata": {
        "id": "i_BGI6u7U8pH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "1zsJzxKi-1ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split text, create embeddings and store in vector store (Load, Chunk and Index)"
      ],
      "metadata": {
        "id": "P-uCkU1-TzA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "embeddings = AzureOpenAIEmbeddings(azure_endpoint=os.environ[\"AZURE_OPENAI_EMBEDDINGS_ENDPOINT\"])\n",
        "print(embeddings)\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "VeZEuwlp_HLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5528722c-5354-4406-f2ea-9e6496e35bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client=<openai.resources.embeddings.Embeddings object at 0x7f1be932b190> async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x7f1be93505e0> model='text-embedding-ada-002' dimensions=None deployment=None openai_api_version='2023-05-15' openai_api_base=None openai_api_type='azure' openai_proxy='' embedding_ctx_length=8191 openai_api_key=SecretStr('**********') openai_organization=None allowed_special=None disallowed_special=None chunk_size=2048 max_retries=2 request_timeout=None headers=None tiktoken_enabled=True tiktoken_model_name=None show_progress_bar=False model_kwargs={} skip_empty=False default_headers=None default_query=None retry_min_seconds=4 retry_max_seconds=20 http_client=None http_async_client=None check_embedding_ctx_length=True azure_endpoint='https://eygroup02.openai.azure.com/openai/deployments/Group2-ada/embeddings?api-version=2023-05-15' azure_ad_token=None azure_ad_token_provider=None validate_base_url=True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create RAG Pipeline"
      ],
      "metadata": {
        "id": "alP4O5NOUruH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the helper functions for RAG pipeline"
      ],
      "metadata": {
        "id": "U6H2nJrOUlNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder"
      ],
      "metadata": {
        "id": "98QmBC5z_KTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt 1 -\n",
        "```Contextualize the user's query based on chat history```"
      ],
      "metadata": {
        "id": "xyrY3T7pT7Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_system_prompt = (\n",
        "    \"What are the two primary challenges\"\n",
        "    \"How to survive in the market, \"\n",
        "    \"strategies to retain customer \"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "_3XmQCo_DG3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Template to guide model behaviour.\n",
        "\n",
        "This template allows to retain context from chat history"
      ],
      "metadata": {
        "id": "cLnQjV9uUgWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    (\"system\", context_system_prompt),\n",
        "    MessagesPlaceholder(\"chat_history\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "]\n",
        "prompt = ChatPromptTemplate.from_messages(messages)"
      ],
      "metadata": {
        "id": "DF5SaOeJDWXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create ```create_history_aware_retriever``` to fetch relevant context from user's document based on the user's query and the conversation history"
      ],
      "metadata": {
        "id": "wLT4KRznUkkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_retriever = create_history_aware_retriever(\n",
        "    llm=model, retriever=retriever, prompt=prompt\n",
        ")\n"
      ],
      "metadata": {
        "id": "i-0FSQuIGudX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt 2 - ```To generate the final answer using the relevant context.```"
      ],
      "metadata": {
        "id": "c6TG0h1dOS4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = (\n",
        "    \"You are a helpful assistant expert churn customer data analysis.\"\n",
        "    \"What are the two primary challenges\"\n",
        "    \"How to survive in the market, \"\n",
        "    \"strategies to retain customer \"\n",
        "    \"\\n\\n\"\n",
        "   \"{context}\"\n",
        ")"
      ],
      "metadata": {
        "id": "HTe7KxUwOGMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "eg9mpLm3e3pr",
        "outputId": "708548ff-3889-429a-91ef-a880359eabf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You are a helpful assistant expert churn customer data analysis.What are the two primary challengesHow to survive in the market, strategies to retain customer \\n\\n{context}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Template to guide model behaviour.\n",
        "\n",
        "This template allows to answer user's query with retrieved information"
      ],
      "metadata": {
        "id": "DgYznrjKUsAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "1wjsd2ckRuNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a ```context_chain```\n",
        "which \"stuffs\" the relevant documents into the language model's prompt, along with the user's query, and returns a response."
      ],
      "metadata": {
        "id": "KCqsg3otW6Ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_chain = create_stuff_documents_chain(\n",
        "    model,\n",
        "    conversation_prompt\n",
        ")"
      ],
      "metadata": {
        "id": "EDyi5h3wDs7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create RAG chain - serves two purposes\n",
        "\n",
        "1 - Uses the ```context_retriever``` to find relevant text chunks from the vector database (Chroma).\n",
        "\n",
        "2 - Passes the retrieved context and the question to the language model to generate an answer."
      ],
      "metadata": {
        "id": "U1yatss_XtNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = create_retrieval_chain(context_retriever,context_chain)"
      ],
      "metadata": {
        "id": "jvOhYajYEafY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pass, Store and Update Chat History"
      ],
      "metadata": {
        "id": "6MLAMAd1X9m6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages to enable dynamic chat history support"
      ],
      "metadata": {
        "id": "tIrGFJGdP-mm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory"
      ],
      "metadata": {
        "id": "nbd9XyoySO5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```RunnableWithMessageHistory``` Wraps the RAG chain to maintain a history of the chat conversation.\n",
        "\n",
        "```get_session_history``` is a helper function to create a ```ChatMessageHistory``` object for a new ```session_id``` or to retrieve ```ChatMessageHistory``` for an existing ```session_id```"
      ],
      "metadata": {
        "id": "9eEUkijlTsmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store = {}\n",
        "\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        ")"
      ],
      "metadata": {
        "id": "quNoZmkwHpxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invoking the conversational RAG chain\n",
        "Presenting answer, and cofiguring a ```session_id``` to store unique chat history"
      ],
      "metadata": {
        "id": "05e2ePYSYM88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_rag_chain.invoke(\n",
        "    {\"input\": \"Which gender are retained?\"},\n",
        "    config={\n",
        "        \"configurable\": {\"session_id\": \"myuniqueid001\"}\n",
        "    },\n",
        ")[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Pt52GjsrHr0e",
        "outputId": "0df01820-991b-4879-ae1c-466448a7f43a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The given information does not provide any data or analysis related to gender and customer retention. Therefore, it is not possible to determine which gender is more likely to be retained based on the given information.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store"
      ],
      "metadata": {
        "id": "pOXjkfjjKj2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe6a1bbb-e1eb-4e96-bbd4-6ccf1cae0114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'myuniqueid001': InMemoryChatMessageHistory(messages=[HumanMessage(content='Which gender are retained?'), AIMessage(content='The given information does not provide any data or analysis related to gender and customer retention. Therefore, it is not possible to determine which gender is more likely to be retained based on the given information.')])}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_rag_chain.invoke(\n",
        "    {\"input\": \"Where this informations are coming from?\"},\n",
        "    config={\n",
        "        \"configurable\": {\"session_id\": \"myuniqueid002\"}\n",
        "    },\n",
        ")[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "493JRVLnrwBA",
        "outputId": "bfc06338-3458-41e2-b018-05954d0c0001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The information provided is sourced from various academic papers and articles on customer churn analysis and prediction. The specific sources are mentioned in the citations provided with each piece of information.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D37UM-6Przqa",
        "outputId": "5c984eb3-8ac3-43d5-e358-603cd65eca85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'myuniqueid001': InMemoryChatMessageHistory(messages=[HumanMessage(content='Which gender are retained?'), AIMessage(content='The given information does not provide any data or analysis related to gender and customer retention. Therefore, it is not possible to determine which gender is more likely to be retained based on the given information.')]),\n",
              " 'myuniqueid002': InMemoryChatMessageHistory(messages=[HumanMessage(content='Where this informations are coming from?'), AIMessage(content='The information provided is sourced from various academic papers and articles on customer churn analysis and prediction. The specific sources are mentioned in the citations provided with each piece of information.')])}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversational_rag_chain.invoke(\n",
        "    {\"input\": \"Where model is used to predict the customer churn rate?\"},\n",
        "    config={\n",
        "        \"configurable\": {\"session_id\": \"myuniqueid002\"}\n",
        "    },\n",
        ")[\"answer\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "gDnuYSNjrX8z",
        "outputId": "acbe7f6d-6a7d-4658-f5d5-3c4eca9be362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In the study mentioned, four different models were used to predict customer churn rate: Classification Tree Model, Random Forest Model, Support Vector Machine (SVM) Model, and Logistic Regression Model. These models were employed to estimate the target churn rate and compare their efficiency and performance in predicting churn within the telecom industry.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GKSuw65rnFC",
        "outputId": "2e591bc8-7727-4091-e8dd-9c189f8a2494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'myuniqueid001': InMemoryChatMessageHistory(messages=[HumanMessage(content='Which gender are retained?'), AIMessage(content='The given information does not provide any data or analysis related to gender and customer retention. Therefore, it is not possible to determine which gender is more likely to be retained based on the given information.'), HumanMessage(content='else'), AIMessage(content='Without specific data or analysis on gender and customer retention, it is difficult to make definitive statements about which gender is more likely to be retained. Retention rates can vary based on various factors such as individual preferences, satisfaction with services, pricing, and overall customer experience. It is important to conduct a comprehensive analysis that includes gender as a variable and factors in other relevant variables to determine any potential correlations between gender and customer retention.')]),\n",
              " 'myuniqueid002': InMemoryChatMessageHistory(messages=[HumanMessage(content='Where this informations are coming from?'), AIMessage(content='The information provided is sourced from various academic papers and articles on customer churn analysis and prediction. The specific sources are mentioned in the citations provided with each piece of information.'), HumanMessage(content='Where model is used to predict the customer churn rate?'), AIMessage(content='In the study mentioned, four different models were used to predict customer churn rate: Classification Tree Model, Random Forest Model, Support Vector Machine (SVM) Model, and Logistic Regression Model. These models were employed to estimate the target churn rate and compare their efficiency and performance in predicting churn within the telecom industry.')])}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  user_input = input(\"Enter 'q' to quit or anything else to continue: \")\n",
        "  if user_input == 'q':\n",
        "    break\n",
        "  else:\n",
        "    res = conversational_rag_chain.invoke(\n",
        "    {\"input\": user_input},\n",
        "    config={\n",
        "        \"configurable\": {\"session_id\": \"myuniqueid001\"}\n",
        "    },\n",
        "    )[\"answer\"]\n",
        "    print(res)\n"
      ],
      "metadata": {
        "id": "TT3VNeGjr2l9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198ba110-4a1a-4485-ba3e-e35f41d637d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter 'q' to quit or anything else to continue: else\n",
            "Without specific data or analysis on gender and customer retention, it is difficult to make definitive statements about which gender is more likely to be retained. Retention rates can vary based on various factors such as individual preferences, satisfaction with services, pricing, and overall customer experience. It is important to conduct a comprehensive analysis that includes gender as a variable and factors in other relevant variables to determine any potential correlations between gender and customer retention.\n",
            "Enter 'q' to quit or anything else to continue: q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_VmnjMR8HEk7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}